[DEFAULT]
# root specifies the root location for all files; testdir specifies ???; mode specifies ???
# For the demo, the root in the current directory
name: DAS
root: .
testdir: .
mode: 0
loglevel: INFO
logfolder: logs

[ENVIRONMENT]
DAS_FRAMEWORK_VERSION: 0.0.1


[geodict]:
#smallest to largest (no spaces)
geolevel_names: Enumdist,County,State,National
#(largest geocode length to smallest, put 1 for top level) (no spaces)
geolevel_leng: 10,6,2,1

[setup]
setup: programs.das_setup.DASDecennialSetup

# Spark config stuff
spark.name: DAS_RA
#local[6] tells spark to run locally with 6 threads
#spark.master: local[9]
#Error , only writes to log if there is an error (INFO, DEBUG, )
spark.loglevel: Error

[reader]
# package(s).module_name.class_name of the reader module
reader: programs.reader.table_reader.DASDecennialReader
###
### List of tables (assuming 3 but might be more)
### These tables have decennial census specific process methods
### Table class methods will likely need to be rewritten for other applications
### 
tables: PersonData UnitData

privacy_table: PersonData
constraint_tables: UnitData

# table_name.class: specify object type of each table
# Geography.class: table.GeographyTable implement later.
PersonData.class: programs.reader.table.DenseHistogramTable
UnitData.class: programs.reader.table.UnitFromPersonTable
# table_name.path - location of dir of filename=======


PersonData.path: s3://uscb-decennial-ite-das/1940/output_P.csv
UnitData.path: s3://uscb-decennial-ite-das/1940/output_H.csv

# file format (assuming all tables will have the same file format)
# we could change this to be "table_name.format_option" if need be.
delimiter: ,
header: True
# If a header exists, this must be set to "True".
# table_name.variables - space delimited ordered list of all the variables in a table.
# Geography.variables: state county block etc will add later.
PersonData.variables: RECTYPE YEAR DATANUM SERIAL PERNUM PERWT RELATE RELATED SEX AGE RACE RACED HISPAN HISPAND CITIZEN HISTID STATEFIP COUNTY TABTRACT ENUMDIST TABBLK GEOCODE GQTYPE
UnitData.variables: RECTYPE YEAR DATANUM SERIAL HHWT STATEFIP COUNTY GQ GQTYPE GQTYPED ENUMDIST TABTRACT TABBLK GEOCODE
linkage: GEOCODE

###
### For each variable in each table the following must be included:
### variable_name.type: "str" or "int"
### variable_name.legal: comma-delimited list of legal value expressions.
###                      an expression may be a single value or a range
###                      defined by two values with a "-" between them.
###                      All ranges are assumed to be closed on both ends.
###                      ie the range 0-115 includes both 0 and 115.
### 
### For each variable the following is optional:
### variable_name.e2e:  special legal value for the 2018 end to end test.
###
### Note: we do not use table_name.variable_name.attribute to define these.
###

RECTYPE.type: str
RECTYPE.legal: H,P
YEAR.type: str
YEAR.legal: 1940
DATANUM.type: str
DATANUM.legal: 02
SERIAL.type: str
SERIAL.legal: 00000001-99999999
HHWT.type: str
HHWT.legal: 0000000100
STATEFIP.type: str
STATEFIP.legal: 00-99
COUNTY.type: str
COUNTY.legal: 0000-9999
GQ.type: int
GQ.legal: 0-9
GQTYPE.type: int
GQTYPE.legal: 0-9
GQTYPED.type: int
GQTYPED.legal: 000-999
ENUMDIST.type: str
ENUMDIST.legal: 0000-9999
GEOCODE.type: str
GEOCODE.legal: 0000000000-9999999999
TABTRACT.type: int
TABTRACT.legal: 00-9999
TABBLK.type: str
TABBLK.legal: 0-9

TABBLKGR.type: int
TABBLKGR.legal: 0-9999

PERNUM.type: str
PERNUM.legal: 0000-9999

PERWT.type:  str
PERWT.legal: 0000000100

SLWT.type: str
SLWT.legal: 0000000100

RELATE.type: str
RELATE.legal: 00-99

RELATED.type: str
RELATED.legal: 0000-9999

SEX.type: str
SEX.legal: 1-2

AGE.type: int
AGE.legal: 000-120

RACE.type: str
RACE.legal: 1-6

RACED.type: str
RACED.legal: 000-999

HISPAN.type: str
HISPAN.legal: 0-4

HISPAND.type:  str
HISPAND.legal: 000-999

CITIZEN.type: str
CITIZEN.legal: 0-4

HISTID.type: str
HISTID.legal: 0-9###

### Some variables must be recoded before the disclosure engine runs.
### These recodes are very specific to the decennial census and in particular
### the 2018 test. However the module is pluggable or may be removed all together
### if no recodes are necessary. The following predisclosure recode guidelines
### are meant to ensure seemless integration of modules.
### (1) variables should not be recoded in place. ie don't overwrite old variables even if all the recode does is change a variables type from str to int so that it can be used as an array index for example. 
### (2) recoder should operate on and return sql Row objects
# package.module_name.class_name for predisclosure recodes
PersonData.recoder: programs.reader.e2e_recoder.votingage_recoder
UnitData.recoder: programs.reader.e2e_recoder.gqunit_recoder
# table_name.recode_variables - list of new variable names
PersonData.recode_variables: VA RACE0 GQTYPE2
UnitData.recode_variables: GQTYPE2

VA: AGE
VA.type: int
VA.legal: 0-1

RACE0: RACE
RACE0.type: int
RACE0.legal: 0-5

GQTYPE2: GQTYPE
GQTYPE2.type: int
GQTYPE2.legal: 0-7

###
### The reader needs to know which variables to build the numpy multiarray over.
### For now the only
# rename geography -> groupby for more general use. 
PersonData.geography: GEOCODE
PersonData.histogram: GQTYPE2 VA HISPAN CITIZEN RACE0

UnitData.geography: geocode
UnitData.histogram: GQTYPE2
UnitData.unique: SERIAL

[engine]
#engine: programs.engine.topdown_engine.TopdownEngine
engine: programs.engine.bottomup_engine.BottomUpEngine

# should we delete the true data after making DP measurments (1 for True or 0 for False)
delete_raw: 0

[budget]
epsilon_budget_total: 1

#budget in topdown order (e.g. US, State, .... , Block)
geolevel_budget_prop: 0.25,0.25,0.25,0.25



# DP queries to create, (or None) (total budget proporiton must add to 1.0)
queriesfile: programs.engine.queries.QueriesCreator1940
DPqueries: , detailed
queriesprop: ,  1.0



[constraints]

theInvariants: tot,va,gqhh_vect,gqhh_tot
invariants: programs.reader.invariants.InvariantsCreator1940
#these are the info to build cenquery.constraint objects

#theConstraints: total,voting_age,hhgq_total_lb,hhgq_total_ub,union_hhgq_lb,hhgq_va_lb,hhgq_va_ub,union_hhgq_va_lb
theConstraints: total,voting_age,hhgq_total_lb,hhgq_total_ub,hhgq_va_lb,hhgq_va_ub

constraints: programs.reader.constraints.ConstraintsCreator1940

[gurobi]
gurobi_lic: $GUROBI_HOME/gurobi_client.lic
gurobi_logfile_name: /mnt/tmp/RAgurobi0.log
OutputFlag: 0
OptimalityTol: 1e-9
BarConvTol: 1e-8
BarQCPConvTol: 0 
BarIterLimit: 1000 
FeasibilityTol: 1e-9
Threads: 1
Presolve: -1
NumericFocus: 3


[writer]
#writer: programs.stub_writer.writer
#writer: programs.mdfwriter.MDFWriter
writer: programs.block_node_writer.BlockNodeWriter
write_type: nodes


# Variables Re-used by multiple writers
# Where the data gets written:
output_path: s3://uscb-decennial-ite-das/users/ashme001/test
output_datafile_name: data

#Write the Data? 0 or 1
produce_flag: 1

#options for block_node_write 
# delete existing file (if one) 0 or 1
overwrite_flag: 1

minimize_nodes: 1
num_parts: 100

#hadoop or s3
filesystem: s3

##options for mdfwriter
split_by_state: True
tables: PersonData UnitData
# only need next option if produce = True
#split_by_state: false
# only need next option if split_by_state = True
state_codes: 02 01 05 04 06 08 09 11 10 12 13 15 19 16 17 18 20 21 22 25 24 23 26 27 29 28 30 37 38 31 33 34 35 32 36 39 40 41 42 72 44 45 46 47 48 49 51 50 53 55 54 56 



[validator]
validator: programs.validator.validator
#validator: programs.stub_validator.validator
results_fname: /mnt/tmp/RA_results

[assessment]

[takedown]
takedown: programs.takedown.takedown
delete_output: True

[experiment]
experiment: programs.experiment.experiment.experiment

run_experiment_flag: 1

experiment_saveloc: s3://uscb-decennial-ite-das/users/ashme001/experiment1940_BU468

# we want to save the = q0,q1original data separate from the privatized data; this allows us to do so
# the original data saveloc only works if the save original data flag is on (1)
save_original_data_flag: 0
original_data_saveloc: s3://uscb-decennial-ite-das/experiments/original_data

# when this is turned on (1), the s3 terminal commands to recursively remove the RDD folders
# will be invoked in order to clear it out before the saveAsPickleFile function gets called
overwrite_flag: 1

filesystem: s3

budget_groups: bu1, bu2, bu3

num_runs: 50

# Budgets follow the order of the geolevels listed in the geodict section
# e.g. Block, Block_Group, Tract, County, State, US

bu1.epsilon_budget_total: 4.0
bu1.geolevel_budget_prop: 0.25, 0.25, 0.25, 0.25
bu1.DPqueries: ,detailed
bu1.queriesprop: , 1.0

bu2.epsilon_budget_total: 6.0
bu2.geolevel_budget_prop: 0.25, 0.25, 0.25, 0.25
bu2.DPqueries: ,detailed
bu2.queriesprop: , 1.0

bu3.epsilon_budget_total: 8.0
bu3.geolevel_budget_prop: 0.25, 0.25, 0.25, 0.25
bu3.DPqueries: ,detailed
bu3.queriesprop: , 1.0



[error_metrics]
error_metrics: programs.metrics.das_error_metrics.error_metrics
