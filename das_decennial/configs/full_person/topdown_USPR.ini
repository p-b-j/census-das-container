[DEFAULT]
# root specifies the root location for all files; testdir specifies ???; mode specifies ???
# For the demo, the root in the current directory
root: .
testdir: .
mode: 0
INCLUDE=default.ini

[logging]
logfilename: DAS
loglevel: INFO
logfolder: logs

[ENVIRONMENT]
DAS_FRAMEWORK_VERSION: 0.0.1
GRB_ISV_NAME: Census
GRB_APP_NAME: DAS
GRB_Env3: 0
GRB_Env4:

[geodict]:
#smallest to largest (no spaces)
geolevel_names: Block,Block_Group,Tract,Tract_Group,County,State,US+PR
#(largest geocode length to smallest, put 1 for top level) (no spaces)
geolevel_leng: 16,12,11,9,5,2,0

[setup]
setup: programs.das_setup.DASDecennialSetup

# Spark config stuff
spark.name: DAS_Full
#local[6] tells spark to run locally with 6 threads
#spark.master: local[9]
#Error , only writes to log if there is an error (INFO, DEBUG, ERROR)
spark.loglevel: ERROR

[reader]
PersonData.path: s3://uscb-decennial-ite-das/title13_input_data/table1a/
UnitData.path: s3://uscb-decennial-ite-das/title13_input_data/table1a/

numReaderPartitions: 5000
readerPartitionLen: 12
validate_input_data_constraints: False


[engine]
#engine: programs.engine.topdown.engine
engine: programs.engine.topdown_engine.TopdownEngine

# should we delete the true data after making DP measurments (1 for True or 0 for False)
delete_raw: 0
save_noisy: 0
reload_noisy: 0
check_budget: off



[schema]
schema: SF1_Person


[budget]
epsilon_budget_total: 1.0


#budget in topdown order (e.g. US, State, .... , Block)
geolevel_budget_prop: 0.15,0.15,0.15,0.15,0.15,0.15,0.1



# start with no queries
DPqueries: detailed
queriesprop: 1.0


[constraints]
#the invariants created, (no spaces)
#theInvariants: #tot,va,gqhh_vect,gqhh_tot
#theInvariants.Block:


#these are the info to build cenquery.constraint objects
#theConstraints: #total,voting_age,hhgq_va_ub,hhgq_va_lb,hhgq_total_lb,hhgq_total_ub,nurse_nva_0
#theConstraints: total,hhgq_total_lb,hhgq_total_ub,nurse_nva_0
#theConstraints.Block:


#minimalSchema:
#minimalSchema:

[gurobi]


[writer]

# Where the data gets written:
output_path: $DAS_S3ROOT/users/$JBID/$MISSION_NAME
output_datafile_name: data
produce_flag: 0

# delete existing file (if one) 0 or 1
overwrite_flag: 1

[validator]
validator: programs.stub_validator.validator
#validator: programs.stub_validator.validator
results_fname: /mnt/tmp/WNS_results

[assessment]

[takedown]
takedown: programs.takedown.takedown
delete_output: True

[experiment]
experiment: programs.experiment.experiment.experiment
run_experiment_flag: 0

[error_metrics]
error_metrics: programs.metrics.accuracy_metrics.AccuracyMetrics
