[DEFAULT]
# root specifies the root location for all files; testdir specifies ???; mode specifies ???
# For the demo, the root in the current directory
INCLUDE=../default.ini

[python]

[logging]
logfilename: DAS
loglevel: INFO
logfolder: logs

[ENVIRONMENT]
DAS_FRAMEWORK_VERSION: 0.0.1
GRB_ISV_NAME: Census
GRB_APP_NAME: DAS
GRB_Env3: 0
GRB_Env4:

[geodict]:
#smallest to largest (no spaces)
geolevel_names: Block,Block_Group,Tract,Tract_Group,County,State
#(largest geocode length to smallest, put 0 for US or US+PR (i.e. above state) level)
geolevel_leng: 16,12,11,9,5,2

[setup]
setup: programs.das_setup.DASDecennialSetup

# Spark config stuff
spark.name: DAS_HDMM_DHCH_TEST
#local[6] tells spark to run locally with 6 threads
#spark.master: local[9]
#Error , only writes to log if there is an error (INFO, DEBUG, ERROR)
spark.loglevel: ERROR

[reader]
INCLUDE=Reader/unit.ini
#######################################################################################################
# Are these paths correct for how the reader works?
#######################################################################################################
Household.path: s3://uscb-decennial-ite-das/title13_input_data/table12a_20190705/ri44.txt
Unit.path: s3://uscb-decennial-ite-das/title13_input_data/table10_20190610/ri44.txt

numReaderPartitions: 5000
readerPartitionLen: 12
validate_input_data_constraints: False

[engine]
engine: programs.engine.hdmm_engine.HDMMEngine

# should we delete the true data after making DP measurments (1 for True or 0 for False)
delete_raw: 0
save_noisy: 0
reload_noisy: 0
check_budget: off

[schema]
schema: Household2010

[budget]
#######################################################################################################
# Changed the PLB to 1 for this time/test run
#######################################################################################################
epsilon_budget_total: .01


#budget in topdown order (e.g. US, State, .... , Block)
geolevel_budget_prop: 0.2,0.2,0.15,0.15,0.15,0.15



# start with no queries
DPqueries: hhsex * hhhisp * hhrace * size * hhtype, elderly * hhsex * hhtype * size, multi * hhhisp * hhrace, hhage * hhtype * hhsex * size, detailed
queriesprop: .3, .25, .1, .25,  .1

[constraints]
#start with none
#the invariants created, (no spaces)
theInvariants.Block: tot_hu,gqhh_vect
#theInvariants.Tract:

#these are the info to build cenquery.constraint objects
theConstraints.Block: total,no_vacant,living_alone,size2,size3,size4,size2plus_notalone,not_multigen,hh_elderly,age_child
#theConstraints.Tract:

#Note: you apparently need to specify this now
minimalSchema: sex

[hdmm]
strategy_type: marginal

[workload]
workload: HOUSEHOLD2010_WORKLOAD


[writer]
#INCLUDE=Writer/default.ini
#######################################################################################################
# Changed the writer to be the pickled block data writer
#######################################################################################################
writer: programs.writer.pickled_block_data_writer.PickledBlockDataWriter

keep_attrs: geocode, raw, syn, _invar
num_parts: 100000
# Where the data gets written:
#######################################################################################################
# TODO: Check that the newer writer config options are correct for this New Mexico full_household test
#######################################################################################################
output_path: s3://uscb-decennial-ite-das/users/sexto015/HDMM-Trial003/
output_datafile_name: data
write_metadata: 0
s3cat: 0
s3cat_suffix: .txt
s3cat_verbose: 1
produce_flag: 1

# delete existing file (if one) 0 or 1
overwrite_flag: 1

[validator]
validator: programs.stub_validator.validator
#validator: programs.stub_validator.validator
results_fname: /mnt/tmp/WNS_results

[assessment]

[takedown]
takedown: programs.takedown.takedown
delete_output: 0

[experiment]
experiment: programs.experiment.experiment_hdmm.ExperimentHDMM
run_experiment_flag: 1
experiment_saveloc: s3://uscb-decennial-ite-das/users/sexto015/experiments/full_household/hdmm_exp001/

#experiment_saveloc: s3://uscb-decennial-ite-das/users/sexto015/experiments/full_household/TestMUD_NM_PLB_Experiment/

# we want to save the = q0,q1original data separate from the privatized data; this allows us to do so
# the original data saveloc only works if the save original data flag is on (1)
save_original_data_flag: 0
original_data_saveloc: s3://uscb-decennial-ite-das/experiments/original_data

# when this is turned on (1), the s3 terminal commands to recursively remove the RDD folders
# will be invoked in order to clear it out before the saveAsPickleFile function gets called
overwrite_flag: 1

filesystem: s3

budget_groups: td001, td01, td025, td05, td1, td2, td4, td8, td16

num_runs: 1

# Budgets follow the order of the geolevels listed in the geodict section
# e.g. Block, Block_Group, Tract, County, State


#.01, .1, .25, .5, 1, 2, 4, 8, 16

td001.epsilon_budget_total: 0.01
td001.geolevel_budget_prop: 0.2, 0.2, 0.15, 0.15, 0.15, 0.15
td001.workload: HOUSEHOLD2010_WORKLOAD



td01.epsilon_budget_total: 0.1
td01.geolevel_budget_prop: 0.2, 0.2, 0.15, 0.15, 0.15, 0.15
td01.workload: HOUSEHOLD2010_WORKLOAD



td025.epsilon_budget_total: 0.25
td025.geolevel_budget_prop: 0.2, 0.2, 0.15, 0.15, 0.15, 0.15
td025.workload: HOUSEHOLD2010_WORKLOAD


td05.epsilon_budget_total: 0.5
td05.geolevel_budget_prop: 0.2, 0.2, 0.15, 0.15, 0.15, 0.15
td05.workload: HOUSEHOLD2010_WORKLOAD


td1.epsilon_budget_total: 1
td1.geolevel_budget_prop: 0.2, 0.2, 0.15, 0.15, 0.15, 0.15
td1.workload: HOUSEHOLD2010_WORKLOAD


td2.epsilon_budget_total: 2
td2.geolevel_budget_prop: 0.2, 0.2, 0.15, 0.15, 0.15, 0.15
td2.workload: HOUSEHOLD2010_WORKLOAD


td4.epsilon_budget_total: 4
td4.geolevel_budget_prop: 0.2, 0.2, 0.15, 0.15, 0.15, 0.15
td4.workload: HOUSEHOLD2010_WORKLOAD


td8.epsilon_budget_total: 8
td8.geolevel_budget_prop: 0.2, 0.2, 0.15, 0.15, 0.15, 0.15
td8.workload: HOUSEHOLD2010_WORKLOAD


td16.epsilon_budget_total: 16
td16.geolevel_budget_prop: 0.2, 0.2, 0.15, 0.15, 0.15, 0.15
td16.workload: HOUSEHOLD2010_WORKLOAD





#td001.DPqueries: hhsex * hhhisp * hhrace * size * hhtype, elderly * hhsex * hhtype * size, multi * hhhisp * hhrace, hhage * hhtype * hhsex * size, detailed
#td001.queriesprop: .3, .25, .1, .25, 0.1

#td8.epsilon_budget_total: 8.0
#td8.geolevel_budget_prop: 0.2, 0.2, 0.15, 0.15, 0.15, 0.15
#td8.DPqueries: hhsex * hhhisp * hhrace * size * hhtype, elderly * hhsex * hhtype * size, multi * hhhisp * hhrace, hhage * hhtype * hhsex * size, detailed
#td8.queriesprop: .3, .25, .1, .25, 0.1


#td05.epsilon_budget_total: 0.5
#td05.geolevel_budget_prop: 0.2, 0.2, 0.15, 0.15, 0.15, 0.15
#td05.DPqueries: hhsex * hhhisp * hhrace * size * hhtype, elderly * hhsex * hhtype * size, multi * hhhisp * hhrace, hhage * hhtype * hhsex * size, detailed
#td05.queriesprop: .3, .25, .1, .25, 0.1


#td1.epsilon_budget_total: 1.0
#td1.geolevel_budget_prop: 0.2, 0.2, 0.15, 0.15, 0.15, 0.15
#td1.DPqueries: hhsex * hhhisp * hhrace * size * hhtype, elderly * hhsex * hhtype * size, multi * hhhisp * hhrace, hhage * hhtype * hhsex * size, detailed
#td1.queriesprop: .3, .25, .1, .25, 0.1

[error_metrics]
error_metrics: programs.metrics.error_metrics_stub.ErrorMetricsStub

#######################################################################################################
# Added this section to explicitly turn off all gurobi stats collection
#######################################################################################################
[gurobi]
