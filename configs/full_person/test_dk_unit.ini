[constraints]
theinvariants.block = gqhh_vect, gqhh_tot
theinvariants.state = tot
theconstraints.block = hhgq_total_lb, hhgq_total_ub, hhgq1_lessthan15, hhgq2_greaterthan25, hhgq3_lessthan20, hhgq5_lt16gt65, hhgq6_lt17gt65
theconstraints.state = total, hhgq_total_lb, hhgq_total_ub
minimalschema = hhgq
root = .
testdir = .
mode = 0

[validator]
validator = programs.stub_validator.validator
results_fname = /mnt/tmp/DK_results
root = .
testdir = .
mode = 0

[error_metrics]
error_metrics = programs.metrics.error_metrics_stub.ErrorMetricsStub
root = .
testdir = .
mode = 0

[writer]
include = Writer/default.ini

writer = programs.writer.pickled_block_data_writer.PickledBlockDataWriter
keep_attrs = geocode, raw, syn
produce_flag = 1
overwrite_flag = 1
num_parts = 500
stats_dir = $DAS_S3ROOT/rpc/upload
output_path = s3://uscb-decennial-ite-das/users/kifer001/test/full_person/TestMPD_RI_PLB_Experiment/td01/run_0000
output_datafile_name = persons
write_metadata = 0
s3cat = 0
s3cat_suffix = .txt
s3cat_verbose = 1
root = .
testdir = .
mode = 0

[takedown]
takedown = programs.takedown.takedown
delete_output = 0
root = .
testdir = .
mode = 0

[geodict]
geolevel_names = Block,Block_Group,Tract,Tract_Group,County,State
geolevel_leng = 16,12,11,9,5,2
root = .
testdir = .
mode = 0

[engine]
engine = programs.engine.topdown_engine.TopdownEngine
delete_raw = 0
save_noisy = 0
reload_noisy = 0
check_budget = on
root = .
testdir = .
mode = 0

[logging]
logfilename = DAS
loglevel = INFO
logfolder = logs
root = .
testdir = .
mode = 0

[experiment]
experiment = programs.experiment.experiment.experiment
run_experiment_flag = 1
experiment_saveloc = s3://uscb-decennial-ite-das/users/kifer001/test/full_person/TestMPD_RI_PLB_Experiment/
original_data_saveloc = s3://uscb-decennial-ite-das/experiments/original_data
save_original_data_flag = 0
overwrite_flag = 1
filesystem = s3
budget_groups = td01
num_runs = 1
td01.epsilon_budget_total = 0.1
td01.geolevel_budget_prop = 0.2, 0.2, 0.15, 0.15, 0.15, 0.15
td01.dpqueries = hhgq, votingage * hispanic * cenrace * citizen, age * sex,detailed
td01.queriesprop = .2, .5, .2,0.1
root = .
testdir = .
mode = 0

[reader]
include = Reader/unit_simple.ini
reader = programs.reader.table_reader.DASDecennialReader
tables = Person Unit
privacy_table = Person
constraint_tables = Unit
person.class = programs.reader.sql_spar_table.SQLSparseHistogramTable
unit.class = programs.reader.sql_spar_table.SQLSparseHistogramTable
person.path = s3://uscb-decennial-ite-das/title13_input_data/table1a_20190709/ri44.txt
unit.path = s3://uscb-decennial-ite-das/title13_input_data/table10/ri44.txt
delimiter = \t
header = True
person.variables = MAFID age geocode white black aian asian nhopi other hispanic sex citizen relation
unit.variables = MAFID geocode gqtype
linkage = geocode
geocode.type = str
geocode.legal = 0000000000000000-9999999999999999
mafid.type = str
mafid.legal = 000000000-999999999
sex.type = int
sex.legal = 0,1
age.type = int
age.legal = 0-115
hispanic.type = int
hispanic.legal = 0,1
white.type = int
white.legal = 0,1
black.type = int
black.legal = 0,1
aian.type = int
aian.legal = 0,1
asian.type = int
asian.legal = 0,1
nhopi.type = int
nhopi.legal = 0,1
other.type = int
other.legal = 0,1
citizen.type = int
citizen.legal = 0,1
relation.type = int
relation.legal = 0-42
ten.type = int
ten.legal = 0-3
gqtype.type = str
gqtype.legal = 000-999
vacs.type = int
vacs.legal = 0-7
person.recoder = programs.reader.e2e_recoder.DHCP_HHGQ_recoder
person.recode_variables = cenrace hhgq
cenrace = white black aian asian nhopi other
hhgq = relation
cenrace.type = int
cenrace.legal = 0-62
hhgq.type = int
hhgq.legal = 0-7
unit.recoder = programs.reader.hh_recoder.Table10RecoderSimple
unit.recode_variables = hhgqinv
hhgqinv = gqtype
hhgqinv.type = int
hhgqinv.legal = 0-7
person.geography = geocode
person.histogram = hhgq sex age hispanic cenrace citizen
numreaderpartitions = 5000
readerpartitionlen = 12
unit.geography = geocode
unit.histogram = hhgqinv
validate_input_data_constraints = False

[setup]
setup = programs.das_setup.DASDecennialSetup
spark.name = DAS_NAT_TEST
spark.loglevel = ERROR

[assessment]

[gurobi]
outputflag = 1
optimalitytol = 1e-9
barconvtol = 1e-8
barqcpconvtol = 0
bariterlimit = 1000
feasibilitytol = 1e-9
threads = 60
presolve = -1
numericfocus = 3
python_presolve = 1

[budget]
epsilon_budget_total = 0.1
# Bounded DP multiplier, aka "elementary" sensitivity used for each individual DP query
bounded_dp_multiplier = 2.0
geolevel_budget_prop = 0.2, 0.2, 0.15, 0.15, 0.15, 0.15

dpqueries = hhgq, votingage * hispanic * cenrace * citizen, age * sex, detailed
queriesprop = .2, .5, .2, 0.1

[schema]
schema = DHCP_HHGQ

[ENVIRONMENT]
das_framework_version = 0.0.1
grb_isv_name = Census
grb_app_name = DAS
grb_env3 = 0
grb_env4 =
